{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:04:52.632787Z",
     "start_time": "2020-09-18T07:04:43.695438Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from deepctr.models import DeepFM\n",
    "from deepctr.feature_column import SparseFeat, DenseFeat, get_feature_names\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:15:50.250845Z",
     "start_time": "2020-09-18T07:15:49.833989Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/final/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:15:51.367383Z",
     "start_time": "2020-09-18T07:15:51.361436Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['방송일시', '노출(분)', '마더코드', '상품코드', '상품명', '상품군', '판매단가', '취급액',\n",
       "       'hour_rank', '공휴일여부', '연휴', 'group', 'within_group', '브랜드', 'NS상품군_대',\n",
       "       'NS상품군_중', 'NS상품군_소', 'prodnames', '평균기온_서울', '최저기온_서울', '최고기온_서울',\n",
       "       '강수량_서울', '최소습도_서울', '평균습도_서울', '평균기온_전국', '최저기온_전국', '최고기온_전국',\n",
       "       '강수량_전국', '최소습도_전국', '평균습도_전국', '성별', '결제방법', '세트여부', 'LG', 'TV',\n",
       "       '울트라HD', '쿠쿠전기밥솥', '3종', '쿠첸', '압력밥솥', '침대', 'LED', '6인용',\n",
       "       'bsi_original', 'bsi_seasonal', 'ccsi', 'PC0', 'PC1', 'PC2', 'PC3',\n",
       "       'PC4', 'PC5', 'PC6', 'cluster', 'TV_상품군_분', 'TV_상품군_평균', 'TV_상품군_최고',\n",
       "       'TV_상품군_총합', 'TV_요일시_분', 'TV_요일시_평균', 'TV_요일시_최고', 'TV_요일시_총합',\n",
       "       'TV_만원대_분', 'TV_만원대_평균', 'TV_만원대_최고', 'TV_만원대_총합', 'TV_월_분', 'TV_월_평균',\n",
       "       'TV_월_최고', 'TV_월_총합', '연', '월', '일', '시간', '분', '요일', '판매단가_100',\n",
       "       '판매단가_만원대', '일별방송순서', '월별방송순서', '노출_5', '노출_10', '계절',\n",
       "       '('유동인구수', '남성', 20)', '('유동인구수', '남성', 30)', '('유동인구수', '남성', 40)',\n",
       "       '('유동인구수', '남성', 50)', '('유동인구수', '남성', 60)', '('유동인구수', '남성', 70)',\n",
       "       '('유동인구수', '여성', 20)', '('유동인구수', '여성', 30)', '('유동인구수', '여성', 40)',\n",
       "       '('유동인구수', '여성', 50)', '('유동인구수', '여성', 60)', '('유동인구수', '여성', 70)',\n",
       "       '전체유동인구수', '평균유동인구수', '유동인구수표준편차'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:15:52.196227Z",
     "start_time": "2020-09-18T07:15:52.174225Z"
    }
   },
   "outputs": [],
   "source": [
    "train = data.loc[data.취급액.isnull()==False]\n",
    "test = data.loc[data.취급액.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한글은 허용되지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:15:53.270934Z",
     "start_time": "2020-09-18T07:15:53.251011Z"
    }
   },
   "outputs": [],
   "source": [
    "col = {x:str(y) for x,y in zip(train.columns,(range(0,len(train.columns))))}\n",
    "train = train.rename(columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:15:54.760197Z",
     "start_time": "2020-09-18T07:15:54.694343Z"
    }
   },
   "outputs": [],
   "source": [
    "sparse_features = ['0','1','2','3','4','5','8','9','10','11','12','13','14','15','16','17',\n",
    "                   '30','31','32','33','34','35','36','37','38','39','40','41','42','43',\n",
    "                   '54',\n",
    "                   '71','72','73','74','75','76',\n",
    "                   '79','80','82'\n",
    "                  ]\n",
    "target = ['7']\n",
    "\n",
    "no_dense_features = sparse_features + target\n",
    "dense_features = [elem for elem in train.columns.tolist() if elem not in no_dense_features]\n",
    "\n",
    "train[sparse_features] = train[sparse_features].fillna('-1', )\n",
    "train[dense_features] = train[dense_features].fillna(0, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:15:56.006789Z",
     "start_time": "2020-09-18T07:15:55.939967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>81</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39900</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>49.5</td>\n",
       "      <td>-1.856842</td>\n",
       "      <td>-5.662105</td>\n",
       "      <td>2.416842</td>\n",
       "      <td>0.072632</td>\n",
       "      <td>40.305263</td>\n",
       "      <td>58.012632</td>\n",
       "      <td>90.5</td>\n",
       "      <td>97</td>\n",
       "      <td>-0.69527</td>\n",
       "      <td>0.536955</td>\n",
       "      <td>0.075706</td>\n",
       "      <td>0.008203</td>\n",
       "      <td>-0.013670</td>\n",
       "      <td>-0.061421</td>\n",
       "      <td>-0.031838</td>\n",
       "      <td>4</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>0.017761</td>\n",
       "      <td>0.083738</td>\n",
       "      <td>19.550562</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.009371</td>\n",
       "      <td>0.033938</td>\n",
       "      <td>18.788212</td>\n",
       "      <td>0.005091</td>\n",
       "      <td>0.017073</td>\n",
       "      <td>0.095699</td>\n",
       "      <td>20.478089</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.012210</td>\n",
       "      <td>0.054928</td>\n",
       "      <td>2019</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>726160.0</td>\n",
       "      <td>824430.0</td>\n",
       "      <td>818520.0</td>\n",
       "      <td>745730.0</td>\n",
       "      <td>467370.0</td>\n",
       "      <td>312130.0</td>\n",
       "      <td>748720.0</td>\n",
       "      <td>808660.0</td>\n",
       "      <td>824250.0</td>\n",
       "      <td>807200.0</td>\n",
       "      <td>529980.0</td>\n",
       "      <td>436050.0</td>\n",
       "      <td>8049200.0</td>\n",
       "      <td>670766.666667</td>\n",
       "      <td>182482.161934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39900</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>49.5</td>\n",
       "      <td>-1.856842</td>\n",
       "      <td>-5.662105</td>\n",
       "      <td>2.416842</td>\n",
       "      <td>0.072632</td>\n",
       "      <td>40.305263</td>\n",
       "      <td>58.012632</td>\n",
       "      <td>90.5</td>\n",
       "      <td>97</td>\n",
       "      <td>-0.69527</td>\n",
       "      <td>0.536955</td>\n",
       "      <td>0.075706</td>\n",
       "      <td>0.008203</td>\n",
       "      <td>-0.013670</td>\n",
       "      <td>-0.061421</td>\n",
       "      <td>-0.031838</td>\n",
       "      <td>4</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>0.017761</td>\n",
       "      <td>0.083738</td>\n",
       "      <td>19.550562</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.009371</td>\n",
       "      <td>0.033938</td>\n",
       "      <td>18.788212</td>\n",
       "      <td>0.005091</td>\n",
       "      <td>0.017073</td>\n",
       "      <td>0.095699</td>\n",
       "      <td>20.478089</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.012210</td>\n",
       "      <td>0.054928</td>\n",
       "      <td>2019</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>726160.0</td>\n",
       "      <td>824430.0</td>\n",
       "      <td>818520.0</td>\n",
       "      <td>745730.0</td>\n",
       "      <td>467370.0</td>\n",
       "      <td>312130.0</td>\n",
       "      <td>748720.0</td>\n",
       "      <td>808660.0</td>\n",
       "      <td>824250.0</td>\n",
       "      <td>807200.0</td>\n",
       "      <td>529980.0</td>\n",
       "      <td>436050.0</td>\n",
       "      <td>8049200.0</td>\n",
       "      <td>670766.666667</td>\n",
       "      <td>182482.161934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39900</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>49.5</td>\n",
       "      <td>-1.856842</td>\n",
       "      <td>-5.662105</td>\n",
       "      <td>2.416842</td>\n",
       "      <td>0.072632</td>\n",
       "      <td>40.305263</td>\n",
       "      <td>58.012632</td>\n",
       "      <td>90.5</td>\n",
       "      <td>97</td>\n",
       "      <td>-0.69527</td>\n",
       "      <td>0.536955</td>\n",
       "      <td>0.075706</td>\n",
       "      <td>0.008203</td>\n",
       "      <td>-0.013670</td>\n",
       "      <td>-0.061421</td>\n",
       "      <td>-0.031838</td>\n",
       "      <td>4</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>0.017761</td>\n",
       "      <td>0.083738</td>\n",
       "      <td>19.550562</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.009371</td>\n",
       "      <td>0.033938</td>\n",
       "      <td>18.788212</td>\n",
       "      <td>0.005091</td>\n",
       "      <td>0.017073</td>\n",
       "      <td>0.095699</td>\n",
       "      <td>20.478089</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.012210</td>\n",
       "      <td>0.054928</td>\n",
       "      <td>2019</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>726160.0</td>\n",
       "      <td>824430.0</td>\n",
       "      <td>818520.0</td>\n",
       "      <td>745730.0</td>\n",
       "      <td>467370.0</td>\n",
       "      <td>312130.0</td>\n",
       "      <td>748720.0</td>\n",
       "      <td>808660.0</td>\n",
       "      <td>824250.0</td>\n",
       "      <td>807200.0</td>\n",
       "      <td>529980.0</td>\n",
       "      <td>436050.0</td>\n",
       "      <td>8049200.0</td>\n",
       "      <td>670766.666667</td>\n",
       "      <td>182482.161934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39900</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>49.5</td>\n",
       "      <td>-1.856842</td>\n",
       "      <td>-5.662105</td>\n",
       "      <td>2.416842</td>\n",
       "      <td>0.072632</td>\n",
       "      <td>40.305263</td>\n",
       "      <td>58.012632</td>\n",
       "      <td>90.5</td>\n",
       "      <td>97</td>\n",
       "      <td>-0.69527</td>\n",
       "      <td>0.536955</td>\n",
       "      <td>0.075706</td>\n",
       "      <td>0.008203</td>\n",
       "      <td>-0.013670</td>\n",
       "      <td>-0.061421</td>\n",
       "      <td>-0.031838</td>\n",
       "      <td>4</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>0.017761</td>\n",
       "      <td>0.083738</td>\n",
       "      <td>19.550562</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.009371</td>\n",
       "      <td>0.033938</td>\n",
       "      <td>18.788212</td>\n",
       "      <td>0.005091</td>\n",
       "      <td>0.017073</td>\n",
       "      <td>0.095699</td>\n",
       "      <td>20.478089</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.012210</td>\n",
       "      <td>0.054928</td>\n",
       "      <td>2019</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>726160.0</td>\n",
       "      <td>824430.0</td>\n",
       "      <td>818520.0</td>\n",
       "      <td>745730.0</td>\n",
       "      <td>467370.0</td>\n",
       "      <td>312130.0</td>\n",
       "      <td>748720.0</td>\n",
       "      <td>808660.0</td>\n",
       "      <td>824250.0</td>\n",
       "      <td>807200.0</td>\n",
       "      <td>529980.0</td>\n",
       "      <td>436050.0</td>\n",
       "      <td>8049200.0</td>\n",
       "      <td>670766.666667</td>\n",
       "      <td>182482.161934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39900</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>49.5</td>\n",
       "      <td>-1.856842</td>\n",
       "      <td>-5.662105</td>\n",
       "      <td>2.416842</td>\n",
       "      <td>0.072632</td>\n",
       "      <td>40.305263</td>\n",
       "      <td>58.012632</td>\n",
       "      <td>90.5</td>\n",
       "      <td>97</td>\n",
       "      <td>-0.69527</td>\n",
       "      <td>0.536955</td>\n",
       "      <td>0.075706</td>\n",
       "      <td>0.008203</td>\n",
       "      <td>-0.013670</td>\n",
       "      <td>-0.061421</td>\n",
       "      <td>-0.031838</td>\n",
       "      <td>4</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>0.017761</td>\n",
       "      <td>0.083738</td>\n",
       "      <td>19.550562</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.009371</td>\n",
       "      <td>0.033938</td>\n",
       "      <td>18.788212</td>\n",
       "      <td>0.005091</td>\n",
       "      <td>0.017073</td>\n",
       "      <td>0.095699</td>\n",
       "      <td>20.478089</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.012210</td>\n",
       "      <td>0.054928</td>\n",
       "      <td>2019</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>726160.0</td>\n",
       "      <td>824430.0</td>\n",
       "      <td>818520.0</td>\n",
       "      <td>745730.0</td>\n",
       "      <td>467370.0</td>\n",
       "      <td>312130.0</td>\n",
       "      <td>748720.0</td>\n",
       "      <td>808660.0</td>\n",
       "      <td>824250.0</td>\n",
       "      <td>807200.0</td>\n",
       "      <td>529980.0</td>\n",
       "      <td>436050.0</td>\n",
       "      <td>8049200.0</td>\n",
       "      <td>670766.666667</td>\n",
       "      <td>182482.161934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35374</th>\n",
       "      <td>148000</td>\n",
       "      <td>-7.9</td>\n",
       "      <td>-10.9</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>39.3</td>\n",
       "      <td>-3.544211</td>\n",
       "      <td>-6.306316</td>\n",
       "      <td>0.846316</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>32.178947</td>\n",
       "      <td>47.684211</td>\n",
       "      <td>91.7</td>\n",
       "      <td>101</td>\n",
       "      <td>-0.01087</td>\n",
       "      <td>-0.472728</td>\n",
       "      <td>0.788651</td>\n",
       "      <td>0.033269</td>\n",
       "      <td>-0.049297</td>\n",
       "      <td>-0.101719</td>\n",
       "      <td>-0.047337</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.017691</td>\n",
       "      <td>0.093975</td>\n",
       "      <td>20.555556</td>\n",
       "      <td>0.004480</td>\n",
       "      <td>0.019184</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>19.989195</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>0.016071</td>\n",
       "      <td>0.075929</td>\n",
       "      <td>19.966879</td>\n",
       "      <td>0.006577</td>\n",
       "      <td>0.021492</td>\n",
       "      <td>0.131403</td>\n",
       "      <td>2019</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>742770.0</td>\n",
       "      <td>827780.0</td>\n",
       "      <td>813940.0</td>\n",
       "      <td>761130.0</td>\n",
       "      <td>482980.0</td>\n",
       "      <td>322080.0</td>\n",
       "      <td>717140.0</td>\n",
       "      <td>780250.0</td>\n",
       "      <td>809350.0</td>\n",
       "      <td>799320.0</td>\n",
       "      <td>530400.0</td>\n",
       "      <td>446410.0</td>\n",
       "      <td>8033550.0</td>\n",
       "      <td>669462.500000</td>\n",
       "      <td>174573.432537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35375</th>\n",
       "      <td>178000</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>64.4</td>\n",
       "      <td>-0.792632</td>\n",
       "      <td>-6.141053</td>\n",
       "      <td>4.009474</td>\n",
       "      <td>0.009474</td>\n",
       "      <td>43.094737</td>\n",
       "      <td>63.494737</td>\n",
       "      <td>89.6</td>\n",
       "      <td>101</td>\n",
       "      <td>-0.01087</td>\n",
       "      <td>-0.472728</td>\n",
       "      <td>0.788651</td>\n",
       "      <td>0.033269</td>\n",
       "      <td>-0.049297</td>\n",
       "      <td>-0.101719</td>\n",
       "      <td>-0.047337</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.017691</td>\n",
       "      <td>0.093975</td>\n",
       "      <td>21.552381</td>\n",
       "      <td>0.005623</td>\n",
       "      <td>0.021631</td>\n",
       "      <td>0.117341</td>\n",
       "      <td>20.167022</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.017886</td>\n",
       "      <td>0.091598</td>\n",
       "      <td>20.478089</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.012210</td>\n",
       "      <td>0.054928</td>\n",
       "      <td>2020</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>738430.0</td>\n",
       "      <td>829640.0</td>\n",
       "      <td>817980.0</td>\n",
       "      <td>751030.0</td>\n",
       "      <td>475910.0</td>\n",
       "      <td>317260.0</td>\n",
       "      <td>753490.0</td>\n",
       "      <td>810320.0</td>\n",
       "      <td>827430.0</td>\n",
       "      <td>811740.0</td>\n",
       "      <td>532310.0</td>\n",
       "      <td>440390.0</td>\n",
       "      <td>8105930.0</td>\n",
       "      <td>675494.166667</td>\n",
       "      <td>181804.026431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35376</th>\n",
       "      <td>168000</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>64.4</td>\n",
       "      <td>-0.792632</td>\n",
       "      <td>-6.141053</td>\n",
       "      <td>4.009474</td>\n",
       "      <td>0.009474</td>\n",
       "      <td>43.094737</td>\n",
       "      <td>63.494737</td>\n",
       "      <td>89.6</td>\n",
       "      <td>101</td>\n",
       "      <td>-0.01087</td>\n",
       "      <td>-0.472728</td>\n",
       "      <td>0.788651</td>\n",
       "      <td>0.033269</td>\n",
       "      <td>-0.049297</td>\n",
       "      <td>-0.101719</td>\n",
       "      <td>-0.047337</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.017691</td>\n",
       "      <td>0.093975</td>\n",
       "      <td>21.552381</td>\n",
       "      <td>0.005623</td>\n",
       "      <td>0.021631</td>\n",
       "      <td>0.117341</td>\n",
       "      <td>21.968216</td>\n",
       "      <td>0.004263</td>\n",
       "      <td>0.018149</td>\n",
       "      <td>0.099745</td>\n",
       "      <td>20.478089</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.012210</td>\n",
       "      <td>0.054928</td>\n",
       "      <td>2020</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>738430.0</td>\n",
       "      <td>829640.0</td>\n",
       "      <td>817980.0</td>\n",
       "      <td>751030.0</td>\n",
       "      <td>475910.0</td>\n",
       "      <td>317260.0</td>\n",
       "      <td>753490.0</td>\n",
       "      <td>810320.0</td>\n",
       "      <td>827430.0</td>\n",
       "      <td>811740.0</td>\n",
       "      <td>532310.0</td>\n",
       "      <td>440390.0</td>\n",
       "      <td>8105930.0</td>\n",
       "      <td>675494.166667</td>\n",
       "      <td>181804.026431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35377</th>\n",
       "      <td>158000</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>64.4</td>\n",
       "      <td>-0.792632</td>\n",
       "      <td>-6.141053</td>\n",
       "      <td>4.009474</td>\n",
       "      <td>0.009474</td>\n",
       "      <td>43.094737</td>\n",
       "      <td>63.494737</td>\n",
       "      <td>89.6</td>\n",
       "      <td>101</td>\n",
       "      <td>-0.01087</td>\n",
       "      <td>-0.472728</td>\n",
       "      <td>0.788651</td>\n",
       "      <td>0.033269</td>\n",
       "      <td>-0.049297</td>\n",
       "      <td>-0.101719</td>\n",
       "      <td>-0.047337</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.017691</td>\n",
       "      <td>0.093975</td>\n",
       "      <td>21.552381</td>\n",
       "      <td>0.005623</td>\n",
       "      <td>0.021631</td>\n",
       "      <td>0.117341</td>\n",
       "      <td>21.673770</td>\n",
       "      <td>0.004012</td>\n",
       "      <td>0.017208</td>\n",
       "      <td>0.094613</td>\n",
       "      <td>20.478089</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.012210</td>\n",
       "      <td>0.054928</td>\n",
       "      <td>2020</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>738430.0</td>\n",
       "      <td>829640.0</td>\n",
       "      <td>817980.0</td>\n",
       "      <td>751030.0</td>\n",
       "      <td>475910.0</td>\n",
       "      <td>317260.0</td>\n",
       "      <td>753490.0</td>\n",
       "      <td>810320.0</td>\n",
       "      <td>827430.0</td>\n",
       "      <td>811740.0</td>\n",
       "      <td>532310.0</td>\n",
       "      <td>440390.0</td>\n",
       "      <td>8105930.0</td>\n",
       "      <td>675494.166667</td>\n",
       "      <td>181804.026431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35378</th>\n",
       "      <td>148000</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>64.4</td>\n",
       "      <td>-0.792632</td>\n",
       "      <td>-6.141053</td>\n",
       "      <td>4.009474</td>\n",
       "      <td>0.009474</td>\n",
       "      <td>43.094737</td>\n",
       "      <td>63.494737</td>\n",
       "      <td>89.6</td>\n",
       "      <td>101</td>\n",
       "      <td>-0.01087</td>\n",
       "      <td>-0.472728</td>\n",
       "      <td>0.788651</td>\n",
       "      <td>0.033269</td>\n",
       "      <td>-0.049297</td>\n",
       "      <td>-0.101719</td>\n",
       "      <td>-0.047337</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.017691</td>\n",
       "      <td>0.093975</td>\n",
       "      <td>21.552381</td>\n",
       "      <td>0.005623</td>\n",
       "      <td>0.021631</td>\n",
       "      <td>0.117341</td>\n",
       "      <td>19.989195</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>0.016071</td>\n",
       "      <td>0.075929</td>\n",
       "      <td>20.478089</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.012210</td>\n",
       "      <td>0.054928</td>\n",
       "      <td>2020</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>738430.0</td>\n",
       "      <td>829640.0</td>\n",
       "      <td>817980.0</td>\n",
       "      <td>751030.0</td>\n",
       "      <td>475910.0</td>\n",
       "      <td>317260.0</td>\n",
       "      <td>753490.0</td>\n",
       "      <td>810320.0</td>\n",
       "      <td>827430.0</td>\n",
       "      <td>811740.0</td>\n",
       "      <td>532310.0</td>\n",
       "      <td>440390.0</td>\n",
       "      <td>8105930.0</td>\n",
       "      <td>675494.166667</td>\n",
       "      <td>181804.026431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35379 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            6   18    19   20   21    22    23        24        25        26  \\\n",
       "0       39900 -5.0  -8.2 -0.6  0.0  34.0  49.5 -1.856842 -5.662105  2.416842   \n",
       "1       39900 -5.0  -8.2 -0.6  0.0  34.0  49.5 -1.856842 -5.662105  2.416842   \n",
       "2       39900 -5.0  -8.2 -0.6  0.0  34.0  49.5 -1.856842 -5.662105  2.416842   \n",
       "3       39900 -5.0  -8.2 -0.6  0.0  34.0  49.5 -1.856842 -5.662105  2.416842   \n",
       "4       39900 -5.0  -8.2 -0.6  0.0  34.0  49.5 -1.856842 -5.662105  2.416842   \n",
       "...       ...  ...   ...  ...  ...   ...   ...       ...       ...       ...   \n",
       "35374  148000 -7.9 -10.9 -4.5  0.0  26.0  39.3 -3.544211 -6.306316  0.846316   \n",
       "35375  178000 -2.2  -6.5  0.3  0.1  37.0  64.4 -0.792632 -6.141053  4.009474   \n",
       "35376  168000 -2.2  -6.5  0.3  0.1  37.0  64.4 -0.792632 -6.141053  4.009474   \n",
       "35377  158000 -2.2  -6.5  0.3  0.1  37.0  64.4 -0.792632 -6.141053  4.009474   \n",
       "35378  148000 -2.2  -6.5  0.3  0.1  37.0  64.4 -0.792632 -6.141053  4.009474   \n",
       "\n",
       "             27         28         29    44   45       46        47        48  \\\n",
       "0      0.072632  40.305263  58.012632  90.5   97 -0.69527  0.536955  0.075706   \n",
       "1      0.072632  40.305263  58.012632  90.5   97 -0.69527  0.536955  0.075706   \n",
       "2      0.072632  40.305263  58.012632  90.5   97 -0.69527  0.536955  0.075706   \n",
       "3      0.072632  40.305263  58.012632  90.5   97 -0.69527  0.536955  0.075706   \n",
       "4      0.072632  40.305263  58.012632  90.5   97 -0.69527  0.536955  0.075706   \n",
       "...         ...        ...        ...   ...  ...      ...       ...       ...   \n",
       "35374  0.160000  32.178947  47.684211  91.7  101 -0.01087 -0.472728  0.788651   \n",
       "35375  0.009474  43.094737  63.494737  89.6  101 -0.01087 -0.472728  0.788651   \n",
       "35376  0.009474  43.094737  63.494737  89.6  101 -0.01087 -0.472728  0.788651   \n",
       "35377  0.009474  43.094737  63.494737  89.6  101 -0.01087 -0.472728  0.788651   \n",
       "35378  0.009474  43.094737  63.494737  89.6  101 -0.01087 -0.472728  0.788651   \n",
       "\n",
       "             49        50        51        52  53        55        56  \\\n",
       "0      0.008203 -0.013670 -0.061421 -0.031838   4  0.004357  0.017761   \n",
       "1      0.008203 -0.013670 -0.061421 -0.031838   4  0.004357  0.017761   \n",
       "2      0.008203 -0.013670 -0.061421 -0.031838   4  0.004357  0.017761   \n",
       "3      0.008203 -0.013670 -0.061421 -0.031838   4  0.004357  0.017761   \n",
       "4      0.008203 -0.013670 -0.061421 -0.031838   4  0.004357  0.017761   \n",
       "...         ...       ...       ...       ...  ..       ...       ...   \n",
       "35374  0.033269 -0.049297 -0.101719 -0.047337   2  0.004535  0.017691   \n",
       "35375  0.033269 -0.049297 -0.101719 -0.047337   2  0.004535  0.017691   \n",
       "35376  0.033269 -0.049297 -0.101719 -0.047337   2  0.004535  0.017691   \n",
       "35377  0.033269 -0.049297 -0.101719 -0.047337   2  0.004535  0.017691   \n",
       "35378  0.033269 -0.049297 -0.101719 -0.047337   2  0.004535  0.017691   \n",
       "\n",
       "             57         58        59        60        61         62        63  \\\n",
       "0      0.083738  19.550562  0.001708  0.009371  0.033938  18.788212  0.005091   \n",
       "1      0.083738  19.550562  0.001708  0.009371  0.033938  18.788212  0.005091   \n",
       "2      0.083738  19.550562  0.001708  0.009371  0.033938  18.788212  0.005091   \n",
       "3      0.083738  19.550562  0.001708  0.009371  0.033938  18.788212  0.005091   \n",
       "4      0.083738  19.550562  0.001708  0.009371  0.033938  18.788212  0.005091   \n",
       "...         ...        ...       ...       ...       ...        ...       ...   \n",
       "35374  0.093975  20.555556  0.004480  0.019184  0.094340  19.989195  0.003769   \n",
       "35375  0.093975  21.552381  0.005623  0.021631  0.117341  20.167022  0.004601   \n",
       "35376  0.093975  21.552381  0.005623  0.021631  0.117341  21.968216  0.004263   \n",
       "35377  0.093975  21.552381  0.005623  0.021631  0.117341  21.673770  0.004012   \n",
       "35378  0.093975  21.552381  0.005623  0.021631  0.117341  19.989195  0.003769   \n",
       "\n",
       "             64        65         66        67        68        69    70  \\\n",
       "0      0.017073  0.095699  20.478089  0.002667  0.012210  0.054928  2019   \n",
       "1      0.017073  0.095699  20.478089  0.002667  0.012210  0.054928  2019   \n",
       "2      0.017073  0.095699  20.478089  0.002667  0.012210  0.054928  2019   \n",
       "3      0.017073  0.095699  20.478089  0.002667  0.012210  0.054928  2019   \n",
       "4      0.017073  0.095699  20.478089  0.002667  0.012210  0.054928  2019   \n",
       "...         ...       ...        ...       ...       ...       ...   ...   \n",
       "35374  0.016071  0.075929  19.966879  0.006577  0.021492  0.131403  2019   \n",
       "35375  0.017886  0.091598  20.478089  0.002667  0.012210  0.054928  2020   \n",
       "35376  0.018149  0.099745  20.478089  0.002667  0.012210  0.054928  2020   \n",
       "35377  0.017208  0.094613  20.478089  0.002667  0.012210  0.054928  2020   \n",
       "35378  0.016071  0.075929  20.478089  0.002667  0.012210  0.054928  2020   \n",
       "\n",
       "             77   78    81        83        84        85        86        87  \\\n",
       "0       30000.0  1.0  20.0  726160.0  824430.0  818520.0  745730.0  467370.0   \n",
       "1       30000.0  1.0  20.0  726160.0  824430.0  818520.0  745730.0  467370.0   \n",
       "2       30000.0  2.0  20.0  726160.0  824430.0  818520.0  745730.0  467370.0   \n",
       "3       30000.0  2.0  20.0  726160.0  824430.0  818520.0  745730.0  467370.0   \n",
       "4       30000.0  3.0  20.0  726160.0  824430.0  818520.0  745730.0  467370.0   \n",
       "...         ...  ...   ...       ...       ...       ...       ...       ...   \n",
       "35374  140000.0  2.0  20.0  742770.0  827780.0  813940.0  761130.0  482980.0   \n",
       "35375  170000.0  1.0  20.0  738430.0  829640.0  817980.0  751030.0  475910.0   \n",
       "35376  160000.0  1.0  20.0  738430.0  829640.0  817980.0  751030.0  475910.0   \n",
       "35377  150000.0  1.0  20.0  738430.0  829640.0  817980.0  751030.0  475910.0   \n",
       "35378  140000.0  1.0  20.0  738430.0  829640.0  817980.0  751030.0  475910.0   \n",
       "\n",
       "             88        89        90        91        92        93        94  \\\n",
       "0      312130.0  748720.0  808660.0  824250.0  807200.0  529980.0  436050.0   \n",
       "1      312130.0  748720.0  808660.0  824250.0  807200.0  529980.0  436050.0   \n",
       "2      312130.0  748720.0  808660.0  824250.0  807200.0  529980.0  436050.0   \n",
       "3      312130.0  748720.0  808660.0  824250.0  807200.0  529980.0  436050.0   \n",
       "4      312130.0  748720.0  808660.0  824250.0  807200.0  529980.0  436050.0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "35374  322080.0  717140.0  780250.0  809350.0  799320.0  530400.0  446410.0   \n",
       "35375  317260.0  753490.0  810320.0  827430.0  811740.0  532310.0  440390.0   \n",
       "35376  317260.0  753490.0  810320.0  827430.0  811740.0  532310.0  440390.0   \n",
       "35377  317260.0  753490.0  810320.0  827430.0  811740.0  532310.0  440390.0   \n",
       "35378  317260.0  753490.0  810320.0  827430.0  811740.0  532310.0  440390.0   \n",
       "\n",
       "              95             96             97  \n",
       "0      8049200.0  670766.666667  182482.161934  \n",
       "1      8049200.0  670766.666667  182482.161934  \n",
       "2      8049200.0  670766.666667  182482.161934  \n",
       "3      8049200.0  670766.666667  182482.161934  \n",
       "4      8049200.0  670766.666667  182482.161934  \n",
       "...          ...            ...            ...  \n",
       "35374  8033550.0  669462.500000  174573.432537  \n",
       "35375  8105930.0  675494.166667  181804.026431  \n",
       "35376  8105930.0  675494.166667  181804.026431  \n",
       "35377  8105930.0  675494.166667  181804.026431  \n",
       "35378  8105930.0  675494.166667  181804.026431  \n",
       "\n",
       "[35379 rows x 57 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[dense_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:16:33.044141Z",
     "start_time": "2020-09-18T07:16:32.918238Z"
    }
   },
   "outputs": [],
   "source": [
    "for feat in sparse_features:\n",
    "    lbe=LabelEncoder()\n",
    "    train[feat] = lbe.fit_transform(train[feat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMax Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:16:34.009026Z",
     "start_time": "2020-09-18T07:16:33.996072Z"
    }
   },
   "outputs": [],
   "source": [
    "max_value = max(train.iloc[:,7]) \n",
    "min_value = min(train.iloc[:,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:16:35.324473Z",
     "start_time": "2020-09-18T07:16:35.060150Z"
    }
   },
   "outputs": [],
   "source": [
    "mms = MinMaxScaler(feature_range=(0,1))\n",
    "train[dense_features] = mms.fit_transform(train[dense_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:16:36.360723Z",
     "start_time": "2020-09-18T07:16:36.356684Z"
    }
   },
   "outputs": [],
   "source": [
    "def min_max_inverse(max_value, min_value, value):\n",
    "    original = value*(max_value - min_value) + min_value \n",
    "    return original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:16:37.417930Z",
     "start_time": "2020-09-18T07:16:37.191481Z"
    }
   },
   "outputs": [],
   "source": [
    "fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=train[feat].nunique(), embedding_dim=4)\n",
    "                         for i,feat in enumerate(sparse_features)] + [DenseFeat(feat, 1, ) \n",
    "                                                                     for feat in dense_features]\n",
    "\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:16:38.272559Z",
     "start_time": "2020-09-18T07:16:38.269567Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "mape = tf.keras.losses.MeanAbsolutePercentageError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:21:10.789616Z",
     "start_time": "2020-09-18T07:16:39.139244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cktna\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "796/796 - 5s - loss: 93.8493 - mean_absolute_percentage_error: 93.8436 - val_loss: 80.0327 - val_mean_absolute_percentage_error: 79.9866\n",
      "Epoch 2/100\n",
      "796/796 - 4s - loss: 74.0521 - mean_absolute_percentage_error: 74.0255 - val_loss: 76.5960 - val_mean_absolute_percentage_error: 76.4893\n",
      "Epoch 3/100\n",
      "796/796 - 4s - loss: 71.7274 - mean_absolute_percentage_error: 71.6839 - val_loss: 74.6824 - val_mean_absolute_percentage_error: 74.5598\n",
      "Epoch 4/100\n",
      "796/796 - 4s - loss: 69.2371 - mean_absolute_percentage_error: 69.1720 - val_loss: 71.8408 - val_mean_absolute_percentage_error: 71.7024\n",
      "Epoch 5/100\n",
      "796/796 - 4s - loss: 65.4872 - mean_absolute_percentage_error: 65.3952 - val_loss: 67.4637 - val_mean_absolute_percentage_error: 67.3097\n",
      "Epoch 6/100\n",
      "796/796 - 4s - loss: 59.7595 - mean_absolute_percentage_error: 59.6356 - val_loss: 61.1401 - val_mean_absolute_percentage_error: 60.9764\n",
      "Epoch 7/100\n",
      "796/796 - 4s - loss: 52.6731 - mean_absolute_percentage_error: 52.5150 - val_loss: 54.3181 - val_mean_absolute_percentage_error: 54.1364\n",
      "Epoch 8/100\n",
      "796/796 - 4s - loss: 46.9847 - mean_absolute_percentage_error: 46.7960 - val_loss: 49.9907 - val_mean_absolute_percentage_error: 49.7690\n",
      "Epoch 9/100\n",
      "796/796 - 4s - loss: 43.6659 - mean_absolute_percentage_error: 43.4533 - val_loss: 47.5725 - val_mean_absolute_percentage_error: 47.3285\n",
      "Epoch 10/100\n",
      "796/796 - 4s - loss: 41.2950 - mean_absolute_percentage_error: 41.0639 - val_loss: 45.7893 - val_mean_absolute_percentage_error: 45.5216\n",
      "Epoch 11/100\n",
      "796/796 - 4s - loss: 39.3636 - mean_absolute_percentage_error: 39.1165 - val_loss: 44.4952 - val_mean_absolute_percentage_error: 44.2042\n",
      "Epoch 12/100\n",
      "796/796 - 4s - loss: 37.6809 - mean_absolute_percentage_error: 37.4195 - val_loss: 43.4358 - val_mean_absolute_percentage_error: 43.1232\n",
      "Epoch 13/100\n",
      "796/796 - 4s - loss: 36.1396 - mean_absolute_percentage_error: 35.8647 - val_loss: 42.6556 - val_mean_absolute_percentage_error: 42.3231\n",
      "Epoch 14/100\n",
      "796/796 - 4s - loss: 34.7062 - mean_absolute_percentage_error: 34.4186 - val_loss: 41.9913 - val_mean_absolute_percentage_error: 41.6436\n",
      "Epoch 15/100\n",
      "796/796 - 4s - loss: 33.3386 - mean_absolute_percentage_error: 33.0387 - val_loss: 41.5013 - val_mean_absolute_percentage_error: 41.1376\n",
      "Epoch 16/100\n",
      "796/796 - 4s - loss: 32.0093 - mean_absolute_percentage_error: 31.6979 - val_loss: 40.9275 - val_mean_absolute_percentage_error: 40.5518\n",
      "Epoch 17/100\n",
      "796/796 - 4s - loss: 30.7375 - mean_absolute_percentage_error: 30.4149 - val_loss: 40.5675 - val_mean_absolute_percentage_error: 40.1803\n",
      "Epoch 18/100\n",
      "796/796 - 4s - loss: 29.5311 - mean_absolute_percentage_error: 29.1978 - val_loss: 40.2779 - val_mean_absolute_percentage_error: 39.8807\n",
      "Epoch 19/100\n",
      "796/796 - 4s - loss: 28.3942 - mean_absolute_percentage_error: 28.0505 - val_loss: 39.9166 - val_mean_absolute_percentage_error: 39.5098\n",
      "Epoch 20/100\n",
      "796/796 - 4s - loss: 27.3159 - mean_absolute_percentage_error: 26.9621 - val_loss: 39.6044 - val_mean_absolute_percentage_error: 39.1893\n",
      "Epoch 21/100\n",
      "796/796 - 4s - loss: 26.2984 - mean_absolute_percentage_error: 25.9352 - val_loss: 39.4918 - val_mean_absolute_percentage_error: 39.0691\n",
      "Epoch 22/100\n",
      "796/796 - 4s - loss: 25.3409 - mean_absolute_percentage_error: 24.9686 - val_loss: 39.3443 - val_mean_absolute_percentage_error: 38.9090\n",
      "Epoch 23/100\n",
      "796/796 - 4s - loss: 24.4388 - mean_absolute_percentage_error: 24.0579 - val_loss: 39.3703 - val_mean_absolute_percentage_error: 38.9266\n",
      "Epoch 24/100\n",
      "796/796 - 4s - loss: 23.5996 - mean_absolute_percentage_error: 23.2104 - val_loss: 39.3100 - val_mean_absolute_percentage_error: 38.8573\n",
      "Epoch 25/100\n",
      "796/796 - 4s - loss: 22.8331 - mean_absolute_percentage_error: 22.4360 - val_loss: 39.3556 - val_mean_absolute_percentage_error: 38.8960\n",
      "Epoch 26/100\n",
      "796/796 - 4s - loss: 22.0904 - mean_absolute_percentage_error: 21.6860 - val_loss: 39.4324 - val_mean_absolute_percentage_error: 38.9602\n",
      "Epoch 27/100\n",
      "796/796 - 4s - loss: 21.4563 - mean_absolute_percentage_error: 21.0448 - val_loss: 39.1743 - val_mean_absolute_percentage_error: 38.6974\n",
      "Epoch 28/100\n",
      "796/796 - 4s - loss: 20.8279 - mean_absolute_percentage_error: 20.4095 - val_loss: 39.2545 - val_mean_absolute_percentage_error: 38.7696\n",
      "Epoch 29/100\n",
      "796/796 - 4s - loss: 20.2524 - mean_absolute_percentage_error: 19.8274 - val_loss: 39.2638 - val_mean_absolute_percentage_error: 38.7743\n",
      "Epoch 30/100\n",
      "796/796 - 4s - loss: 19.7194 - mean_absolute_percentage_error: 19.2884 - val_loss: 39.4319 - val_mean_absolute_percentage_error: 38.9332\n",
      "Epoch 31/100\n",
      "796/796 - 4s - loss: 19.2100 - mean_absolute_percentage_error: 18.7733 - val_loss: 39.4302 - val_mean_absolute_percentage_error: 38.9239\n",
      "Epoch 32/100\n",
      "796/796 - 4s - loss: 18.7332 - mean_absolute_percentage_error: 18.2909 - val_loss: 39.3550 - val_mean_absolute_percentage_error: 38.8459\n",
      "Epoch 33/100\n",
      "796/796 - 4s - loss: 18.2964 - mean_absolute_percentage_error: 17.8488 - val_loss: 39.2608 - val_mean_absolute_percentage_error: 38.7474\n",
      "Epoch 34/100\n",
      "796/796 - 4s - loss: 17.8776 - mean_absolute_percentage_error: 17.4249 - val_loss: 39.5255 - val_mean_absolute_percentage_error: 39.0040\n",
      "Epoch 35/100\n",
      "796/796 - 4s - loss: 17.4844 - mean_absolute_percentage_error: 17.0268 - val_loss: 39.4442 - val_mean_absolute_percentage_error: 38.9194\n",
      "Epoch 36/100\n",
      "796/796 - 4s - loss: 17.1319 - mean_absolute_percentage_error: 16.6696 - val_loss: 39.4254 - val_mean_absolute_percentage_error: 38.8949\n",
      "Epoch 37/100\n",
      "796/796 - 4s - loss: 16.7656 - mean_absolute_percentage_error: 16.2988 - val_loss: 39.4529 - val_mean_absolute_percentage_error: 38.9167\n",
      "Epoch 38/100\n",
      "796/796 - 4s - loss: 16.4383 - mean_absolute_percentage_error: 15.9671 - val_loss: 39.3607 - val_mean_absolute_percentage_error: 38.8185\n",
      "Epoch 39/100\n",
      "796/796 - 4s - loss: 16.1382 - mean_absolute_percentage_error: 15.6628 - val_loss: 39.6141 - val_mean_absolute_percentage_error: 39.0677\n",
      "Epoch 40/100\n",
      "796/796 - 4s - loss: 15.8676 - mean_absolute_percentage_error: 15.3884 - val_loss: 39.4260 - val_mean_absolute_percentage_error: 38.8746\n",
      "Epoch 41/100\n",
      "796/796 - 4s - loss: 15.5822 - mean_absolute_percentage_error: 15.0992 - val_loss: 39.4965 - val_mean_absolute_percentage_error: 38.9431\n",
      "Epoch 42/100\n",
      "796/796 - 4s - loss: 15.3573 - mean_absolute_percentage_error: 14.8706 - val_loss: 39.6356 - val_mean_absolute_percentage_error: 39.0770\n",
      "Epoch 43/100\n",
      "796/796 - 4s - loss: 15.1029 - mean_absolute_percentage_error: 14.6127 - val_loss: 39.7382 - val_mean_absolute_percentage_error: 39.1765\n",
      "Epoch 44/100\n",
      "796/796 - 4s - loss: 14.8870 - mean_absolute_percentage_error: 14.3935 - val_loss: 39.5930 - val_mean_absolute_percentage_error: 39.0291\n",
      "Epoch 45/100\n",
      "796/796 - 4s - loss: 14.6859 - mean_absolute_percentage_error: 14.1894 - val_loss: 39.3146 - val_mean_absolute_percentage_error: 38.7452\n",
      "Epoch 46/100\n",
      "796/796 - 4s - loss: 14.5138 - mean_absolute_percentage_error: 14.0143 - val_loss: 39.3212 - val_mean_absolute_percentage_error: 38.7505\n",
      "Epoch 47/100\n",
      "796/796 - 4s - loss: 14.3303 - mean_absolute_percentage_error: 13.8280 - val_loss: 39.4515 - val_mean_absolute_percentage_error: 38.8792\n",
      "Epoch 48/100\n",
      "796/796 - 4s - loss: 14.1648 - mean_absolute_percentage_error: 13.6597 - val_loss: 39.2772 - val_mean_absolute_percentage_error: 38.7028\n",
      "Epoch 49/100\n",
      "796/796 - 4s - loss: 14.0382 - mean_absolute_percentage_error: 13.5309 - val_loss: 39.3590 - val_mean_absolute_percentage_error: 38.7825\n",
      "Epoch 50/100\n",
      "796/796 - 4s - loss: 13.8749 - mean_absolute_percentage_error: 13.3652 - val_loss: 39.4337 - val_mean_absolute_percentage_error: 38.8511\n",
      "Epoch 51/100\n",
      "796/796 - 4s - loss: 13.7660 - mean_absolute_percentage_error: 13.2540 - val_loss: 39.1941 - val_mean_absolute_percentage_error: 38.6139\n",
      "Epoch 52/100\n",
      "796/796 - 4s - loss: 13.6351 - mean_absolute_percentage_error: 13.1209 - val_loss: 39.1224 - val_mean_absolute_percentage_error: 38.5373\n",
      "Epoch 53/100\n",
      "796/796 - 4s - loss: 13.5326 - mean_absolute_percentage_error: 13.0164 - val_loss: 39.1236 - val_mean_absolute_percentage_error: 38.5405\n",
      "Epoch 54/100\n",
      "796/796 - 4s - loss: 13.4176 - mean_absolute_percentage_error: 12.8995 - val_loss: 39.0725 - val_mean_absolute_percentage_error: 38.4797\n",
      "Epoch 55/100\n",
      "796/796 - 4s - loss: 13.3050 - mean_absolute_percentage_error: 12.7849 - val_loss: 38.9493 - val_mean_absolute_percentage_error: 38.3564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "796/796 - 4s - loss: 13.2397 - mean_absolute_percentage_error: 12.7177 - val_loss: 38.9985 - val_mean_absolute_percentage_error: 38.4063\n",
      "Epoch 57/100\n",
      "796/796 - 4s - loss: 13.1262 - mean_absolute_percentage_error: 12.6025 - val_loss: 39.1141 - val_mean_absolute_percentage_error: 38.5212\n",
      "Epoch 58/100\n",
      "796/796 - 4s - loss: 13.0618 - mean_absolute_percentage_error: 12.5364 - val_loss: 38.9571 - val_mean_absolute_percentage_error: 38.3641\n",
      "Epoch 59/100\n",
      "796/796 - 4s - loss: 12.9698 - mean_absolute_percentage_error: 12.4428 - val_loss: 38.8854 - val_mean_absolute_percentage_error: 38.2894\n",
      "Epoch 60/100\n",
      "796/796 - 4s - loss: 12.8959 - mean_absolute_percentage_error: 12.3673 - val_loss: 38.9909 - val_mean_absolute_percentage_error: 38.3953\n",
      "Epoch 61/100\n",
      "796/796 - 4s - loss: 12.8239 - mean_absolute_percentage_error: 12.2939 - val_loss: 38.9479 - val_mean_absolute_percentage_error: 38.3514\n",
      "Epoch 62/100\n",
      "796/796 - 4s - loss: 12.7417 - mean_absolute_percentage_error: 12.2103 - val_loss: 38.7061 - val_mean_absolute_percentage_error: 38.1094\n",
      "Epoch 63/100\n",
      "796/796 - 4s - loss: 12.7105 - mean_absolute_percentage_error: 12.1777 - val_loss: 38.8790 - val_mean_absolute_percentage_error: 38.2796\n",
      "Epoch 64/100\n",
      "796/796 - 4s - loss: 12.6202 - mean_absolute_percentage_error: 12.0861 - val_loss: 38.9779 - val_mean_absolute_percentage_error: 38.3772\n",
      "Epoch 65/100\n",
      "796/796 - 4s - loss: 12.5938 - mean_absolute_percentage_error: 12.0585 - val_loss: 38.8129 - val_mean_absolute_percentage_error: 38.2140\n",
      "Epoch 66/100\n",
      "796/796 - 4s - loss: 12.5243 - mean_absolute_percentage_error: 11.9878 - val_loss: 38.8565 - val_mean_absolute_percentage_error: 38.2579\n",
      "Epoch 67/100\n",
      "796/796 - 4s - loss: 12.4747 - mean_absolute_percentage_error: 11.9371 - val_loss: 38.8746 - val_mean_absolute_percentage_error: 38.2694\n",
      "Epoch 68/100\n",
      "796/796 - 4s - loss: 12.4142 - mean_absolute_percentage_error: 11.8753 - val_loss: 38.8469 - val_mean_absolute_percentage_error: 38.2467\n",
      "Epoch 69/100\n",
      "796/796 - 4s - loss: 12.3878 - mean_absolute_percentage_error: 11.8477 - val_loss: 38.9638 - val_mean_absolute_percentage_error: 38.3580\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-c81589bfb782>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m history = model.fit(x_train_model_input, x_train[target].values,\n\u001b[1;32m---> 11\u001b[1;33m                    batch_size=32, epochs=100, verbose=2, validation_split=0.1)\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_train, test = train_test_split(train, test_size=0.2)\n",
    "\n",
    "x_train_model_input = {name:x_train[name].values for name in x_train[dense_features].columns.tolist() + x_train[sparse_features].columns.tolist()}\n",
    "test_model_input = {name:test[name].values for name in x_train[dense_features].columns.tolist() + x_train[sparse_features].columns.tolist()}\n",
    "\n",
    "model = DeepFM(linear_feature_columns, dnn_feature_columns, task=\"regression\")\n",
    "model.compile(optimizer=\"adam\", loss= mape,\n",
    "             metrics=[mape], )\n",
    "\n",
    "history = model.fit(x_train_model_input, x_train[target].values,\n",
    "                   batch_size=32, epochs=100, verbose=2, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-20T07:50:58.360340Z",
     "start_time": "2020-09-20T07:50:54.202010Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cktna\\AppData\\Roaming\\Python\\Python36\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import fire\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from metrics import mape_transform, mape\n",
    "from utils import *\n",
    "from sklearn.ensemble import RandomForestRegressor as rf\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-20T07:50:58.380288Z",
     "start_time": "2020-09-20T07:50:58.377296Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\"max_depth\":6,\n",
    "              \"min_samples_leaf\": 2,\n",
    "              \"boostrap\":\"True\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-20T07:50:59.070496Z",
     "start_time": "2020-09-20T07:50:59.060551Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(trainset, testset, verbose_eval =False):\n",
    "    test_result ={}\n",
    "    \n",
    "    model = rf(params = params)\n",
    "    x_train = trainset.drop(columns=[\"취급액\",\"로그_취급액\"])\n",
    "    y_train = trainset.loc[\"로그_취급액\"]\n",
    "    rf.fit(x_train, y_train)\n",
    "    pred= rf.predict(testset.drop(columns=[\"취급액\",\"로그_취급액\"]))\n",
    "    true = testset.loc[\"로그_취급액\"]\n",
    "    scores = np.round(mape(np.exp(true), np.exp(pred)), 4)\n",
    "    return model, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-20T07:50:59.918928Z",
     "start_time": "2020-09-20T07:50:59.894996Z"
    }
   },
   "outputs": [],
   "source": [
    "class randomforest:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        \n",
    "    def tsCV(self, data, interval, imputation=False, params=params, verbose=False):\n",
    "        \n",
    "        data = get_data(data)\n",
    "        scores = []\n",
    "        normal_scores = []\n",
    "        null_scores = []\n",
    "        rounds = []\n",
    "        \n",
    "        if verbose:\n",
    "            row_format = \"{:^15}|{:^15}|{:^15}|{:^15}\"\n",
    "            print(row_format.format(\"target_month\", \"normal mape\", \"null mape\", \"mape\"))\n",
    "            print(row_format.format(\"=\" * 15, \"=\" * 15, \"=\" * 15, \"=\" * 15))\n",
    "        min_month = data.loc[:,'월'].values.astype(int).min()\n",
    "        max_month = data.loc[:,'월'].values.astype(int).max()\n",
    "        \n",
    "        for target_month in range(min_month+1, max_month+1):\n",
    "            if interval == 0:\n",
    "                start_month = min_month\n",
    "            else:\n",
    "                start_month = target_month - interval\n",
    "                if start_month < min_month:\n",
    "                    continue\n",
    "                    \n",
    "            # split dataset\n",
    "            trainset, testset = ts_split(data, start_month, target_month)\n",
    "            testset = testset.assing(is_normal=testset.상품명.isin(trainset.상품명))\n",
    "            \n",
    "            # imputation\n",
    "            if imputation:\n",
    "                testset = impute(trainset, testset)\n",
    "                \n",
    "            # encode categorical features\n",
    "            cat_vars = [x for x in data.columns if isinstance(data[x].dtype, pd.CategoricalDtype)]\n",
    "            trainset, testset = encode_categorical_features(trainset, testset, cat_vars)\n",
    "            \n",
    "            # split normal/null data\n",
    "            normal = testset.query(\"is_normal == True\").drop(\"is_normal\", axis=1)\n",
    "            null = testset.query(\"is_normal == False\").drop(\"is_normal\", axis=1)\n",
    "            \n",
    "            n_normal = normal.shape[0]\n",
    "            n_null = null.shape[0]\n",
    "            \n",
    "            # train & valid w/ normal dataset\n",
    "            model, normal_score = train(trainset, normal, verbose_eval = False)\n",
    "            \n",
    "            # valid w/ null dataset\n",
    "            true = null.로그_취급액.values\n",
    "            pred = model.predict(null.drop([\"로그_취급액\"], axis=1))\n",
    "            null_score = round(mape(np.exp(true), np.exp(pred)), 4)\n",
    "            \n",
    "            score = round((normal_score * n_normal + null_score*n_null)/(n_normal + n_null), 4 )\n",
    "            \n",
    "            normal_scores.append(normal_score)\n",
    "            null_scores.append(null_score)\n",
    "            scores.append(score)\n",
    "            \n",
    "            \n",
    "            if verbose:\n",
    "                print(row_format.format(target_month, normal_score, null_score, score, boosting_round))\n",
    "                \n",
    "            mean_score = np.round(np.mean(scores), 4)\n",
    "            mean_normal_score = np.round(np.mean(normal_scores), 4)\n",
    "            mean_null_score = np.round(np.mean(null_scores), 4)\n",
    "            \n",
    "            if verbose:\n",
    "                print(row_format.format(\"=\" * 15, \"=\" * 15, \"=\" * 15, \"=\" * 15))\n",
    "            print(row_format.format(\"mean\", mean_normal_score, mean_null_score, mean_score))\n",
    "        return mean_score, mean_normal_score, mean_null_score\n",
    "    \n",
    "    def fit(self, trainset, testset):\n",
    "        model, score = train(trainset, testset, verbose_eval=100)\n",
    "        self.model = model\n",
    "        return self\n",
    "    \n",
    "    def predict(self, data):\n",
    "        assert self.model is not None\n",
    "        return self.model.predict(data)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    randomforest\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-20T07:53:30.740961Z",
     "start_time": "2020-09-20T07:53:30.177875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " target_month  |  normal mape  |   null mape   |     mape      \n",
      "===============|===============|===============|===============\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'월'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-f7e8b390dce2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrandomforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'data.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimputation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-df12f0b06115>\u001b[0m in \u001b[0;36mtsCV\u001b[1;34m(self, data, interval, imputation, params, verbose)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;31m# split dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mtrainset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mts_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_month\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_month\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[0mtestset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_normal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtestset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m상품명\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m상품명\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\jupyter notebook\\modeling\\utils.py\u001b[0m in \u001b[0;36mts_split\u001b[1;34m(data, start_month, target_month)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mts_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_month\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_month\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0mtrainset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'월'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtarget_month\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'월'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mstart_month\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[0mtestset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'월'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtarget_month\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    877\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 879\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1110\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1057\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m         \u001b[1;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1059\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1060\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1061\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mxs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   3486\u001b[0m             \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_level\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3487\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3488\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3490\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\range.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    356\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '월'"
     ]
    }
   ],
   "source": [
    "randomforest.tsCV(rf, data = 'data.csv', interval= 0, imputation=True, params=params, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = {\"max_depth\":6,\n",
    "              \"min_samples_leaf\": 2,\n",
    "              \"boostrap\":\"True\"}\n",
    "\n",
    "def objective(hyperparameters, iteration, n_splits=5):\n",
    "    if 'n_estimators' in hyperparamters.keys():\n",
    "        del hyperparameters['n_estimators']\n",
    "        \n",
    "    \n",
    "    for i in range(2,13):\n",
    "        train = data.loc[data.월.astype(int) < i]\n",
    "        valid = data.loc[data.월.astype(int) == i]\n",
    "        \n",
    "        x_train = train.drop(columns=[\"취급액\"])\n",
    "        y_train = train.loc[\"취급액\"]\n",
    "        \n",
    "        rf_model = rf(**hyperparameters)\n",
    "        rf_model.fit(x_train, y_train)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def random_search(params_grid, max_evals = MAX_EVALS):\n",
    "    results = pd.DataFrame(columns = [\"score\",\"params\",\"iterations\",\n",
    "                                     index = list(range(MAX_EVALS))])\n",
    "    \n",
    "    hyperparameters = {k:random.sample(v, 1)[0] for k,v in params_grid.items()}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainset, testset, verbose_eval = False):\n",
    "    test_result = {}\n",
    "    model = rf(params = params,\n",
    "                    train_set =  trainset,\n",
    "                    valid_sets = test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestModel:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        \n",
    "    def tsCV(self, data, inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(hyperparameters, iteration):\n",
    "    if 'n_estimators' in hyperparamters.keys():\n",
    "        del hyperparameters['n_estimators']\n",
    "        \n",
    "    cv_results = rf.cv(hyperparameters, train_set, nfold= N_FOLDS, )\n",
    "\n",
    "\n",
    "\n",
    "def random_search(params_grid, max_evals = MAX_EVALS):\n",
    "    results = pd.DataFrame(columns = [\"score\",\"params\",\"iterations\",\n",
    "                                     index = list(range(MAX_EVALS))])\n",
    "    \n",
    "    hyperparameters = {k:random.sample(v, 1)[0] for k,v in params_grid.items()}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T05:49:55.887522Z",
     "start_time": "2020-09-18T05:49:55.882392Z"
    }
   },
   "outputs": [],
   "source": [
    "def rf_run(data):\n",
    "    model = RandomForestRegressor(criterion='mape')\n",
    "    \n",
    "    for i in range(2, 13):\n",
    "        train = data.loc[lambda x:x.월 < i]\n",
    "        test = data.loc[lambda x:x.월 == i]\n",
    "    \n",
    "        x_train = train.drop(columns=[\"취급액\"])\n",
    "        y_train = train.loc[:, \"취급액\"]\n",
    "    \n",
    "        params_grid = {\"max_depth\": [5,6,7],\n",
    "                      \"min_samples_split\":[2,3,4]}\n",
    "        \n",
    "    model.fit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
